S3static sync tests
===================

We have a same directory and a test bucket (in a faux s3).

    >>> import os, mock
    >>> os.mkdir('sample')
    >>> t = 1379885832.0
    >>> with mock.patch('time.time', return_value=t):
    ...     mkfile('sample/f1')
    ...     mkfile('sample/d1/f1')
    ...     mkfile('sample/d1/d2/f1')
    ...     mkfile('sample/f2')
    ...     mkfile('sample/d1/f2')
    ...     mkfile('sample/d1/d2/f2')

Cuz we're mean, we'll create a broken symlink:

    >>> os.symlink('lose', 'sample/d1/hahaha')

Later:

    >>> t += 3600

We'll sync to our faux bucket:

    >>> import zc.s3staticsync

    >>> t += 30
    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main([os.path.abspath('sample'), 'test'])
    ... # doctest: +ELLIPSIS
    bad file 'd1/hahaha'
    Traceback (most recent call last):
    ...
    OSError: [Errno 2] No such file or directory: '.../sample/d1/hahaha'

Note that we logged an exception for the bad link, but we kept going.

    >>> os.remove('sample/d1/hahaha')

Let's check what we have in our bucket:

    >>> import boto.s3.connection
    >>> s3 = boto.s3.connection.S3Connection()
    >>> bucket = s3.get_bucket('test')

    >>> for k in bucket:
    ...     print k.key
    ...     k.check('sample')
    d1/d2/f1
    d1/d2/f2
    d1/f1
    d1/f2
    f1
    f2

We did 6 puts and no deletes:

    >>> bucket.puts, bucket.deletes
    (6, 0)

Time passes and we so it all again:

    >>> t += 1800
    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main([os.path.abspath('sample'), 'test'])

Nothing should have been put or deleted:

    >>> bucket.puts, bucket.deletes
    (6, 0)


 Let's make some changes and make sure they're reflected:

    >>> t += 1000
    >>> with mock.patch('time.time', return_value=t):
    ...     mkfile('sample/d1/d2/f1')
    ...     mkfile('sample/f3')
    ...     mkfile('sample/d1/f3')
    ...     mkfile('sample/d1/d2/f3')

    >>> os.remove('sample/f2')
    >>> os.remove('sample/d1/f2')
    >>> os.remove('sample/d1/d2/f2')


    >>> with mock.patch('time.time', return_value=t+800):
    ...    zc.s3staticsync.main([os.path.abspath('sample'), 'test'])

    >>> for k in bucket:
    ...     print k.key
    ...     k.check('sample')
    d1/d2/f1
    d1/d2/f3
    d1/f1
    d1/f3
    f1
    f3

    >>> bucket.puts, bucket.deletes
    (10, 3)

There's a kinda weird case.  We compare file modification time to s3
modification time. To account for that, and for clocks being out of
sync, we add a fudge factor to the modification time. This causes
newly modified files to be uploaded twice:

    >>> t += 1800
    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main([os.path.abspath('sample'), 'test'])
    >>> bucket.puts, bucket.deletes
    (14, 3)

But only twice:

    >>> t += 1800
    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main([os.path.abspath('sample'), 'test'])
    >>> bucket.puts, bucket.deletes
    (14, 3)

Emptying a bucket
=================

An easy way to empty a bucket is to sync from an empty directory. :)

    >>> os.mkdir('empty')
    >>> zc.s3staticsync.main(['empty', 'test'])
    >>> list(bucket)
    []

Prefix duplication
==================

Sometimes, if you've been very bad, you may need to duplicate keys.
In a web server, you might hace rules to rewrite URLs.

You can provide some prefix pairs on the command line. When adding or
removing keys, you can add and remove duplicate paths starting with a
given prefix to another prefix.

    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main(
    ...       [os.path.abspath('sample'), 'test',
    ...       '=dup/', '=dup2/', 'd1/d2/=d2/',
    ...       ])

Here we duplicated everything to dup1 and dup2, and
duplicates everything in d1/d2 to a top level d2 directory.

    >>> for k in bucket:
    ...     print k.key
    d1/d2/f1
    d1/d2/f3
    d1/f1
    d1/f3
    d2/f1
    d2/f3
    dup/d1/d2/f1
    dup/d1/d2/f3
    dup/d1/f1
    dup/d1/f3
    dup/f1
    dup/f3
    dup2/d1/d2/f1
    dup2/d1/d2/f3
    dup2/d1/f1
    dup2/d1/f3
    dup2/f1
    dup2/f3
    f1
    f3

    >>> for k in bucket.list('dup/'):
    ...     k.check('sample', 'dup/')

    >>> for k in bucket.list('dup2/'):
    ...     k.check('sample', 'dup2/')

    >>> for k in bucket.list('d1/'):
    ...     k.check('sample')

Do it again, for good measure:

    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main(
    ...       [os.path.abspath('sample'), 'test',
    ...       '=dup/', '=dup2/', 'd1/d2/=d2/',
    ...       ])
    >>> for k in bucket:
    ...     print k.key
    d1/d2/f1
    d1/d2/f3
    d1/f1
    d1/f3
    d2/f1
    d2/f3
    dup/d1/d2/f1
    dup/d1/d2/f3
    dup/d1/f1
    dup/d1/f3
    dup/f1
    dup/f3
    dup2/d1/d2/f1
    dup2/d1/d2/f3
    dup2/d1/f1
    dup2/d1/f3
    dup2/f1
    dup2/f3
    f1
    f3

Cleanup:

    >>> zc.s3staticsync.main(
    ...       ['empty', 'test',
    ...       '=dup/', '=dup2/', 'd1/d2/=d2/',
    ...       ])
    >>> list(bucket)
    []

Important note!
  If you change the prefix-rewriting configuration, it will only be
  honored for new changes.

Avoiding deletes
================

If you supply the -D option, no keys in S3 will be deleted:

    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main(
    ...       [os.path.abspath('sample'), 'test',
    ...       ])
    >>> for k in bucket:
    ...     print k.key
    d1/d2/f1
    d1/d2/f3
    d1/f1
    d1/f3
    f1
    f3


    >>> t += 3000
    >>> with mock.patch('time.time', return_value=t):
    ...     mkfile('sample/f2')
    ...     mkfile('sample/d1/f2')
    ...     mkfile('sample/d1/d2/f2')
    >>> os.remove('sample/f3')
    >>> os.remove('sample/d1/f3')
    >>> os.remove('sample/d1/d2/f3')


    >>> with mock.patch('time.time', return_value=t):
    ...    zc.s3staticsync.main(
    ...       [os.path.abspath('sample'), 'test', '-D'
    ...       ])
    >>> for k in bucket:
    ...     print k.key
    d1/d2/f1
    d1/d2/f2
    d1/d2/f3
    d1/f1
    d1/f2
    d1/f3
    f1
    f2
    f3
